---
title: Palmer Penguins Modeling
jupyter: python3
format:
  html:
    embed-resources: true
---


Import the Palmer Penguins dataset and print out the first few rows.

Suppose we want to predict `bill_depth_mm` using the other variables in the dataset.

**Dummify** all variables that require this.


```{python}
#| colab: {base_uri: https://localhost:8080/}
# Code Here
!pip install palmerpenguins
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, r2_score
from sklearn.model_selection import train_test_split
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
from palmerpenguins import load_penguins
penguins = load_penguins()
penguins.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 226}
# dummify species, island, and sex
penguins = pd.get_dummies(penguins, drop_first=True)
penguins = penguins.dropna()
penguins = penguins.astype(int)
penguins.head()
```

Let's use the other variables to predict `bill_depth_mm`. Prepare your data and fit the following models on a training dataset subset of the entire dataset:

* Four different models, each containing a different set of predictor variables

Create a plot like the right plot of Fig 1. in our `Model Validation` chapter with the training and test error plotted for each of your four models.

Which of your models was best?

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 175}
y_train = penguins["bill_depth_mm"]
X_train = penguins.drop(columns=["bill_depth_mm"])
X_train, X_test, y_train, y_test = train_test_split(
    X_train, y_train, test_size=0.2, random_state=42)

models = {
    "Model 1": ["bill_length_mm"],
    "Model 2": ["bill_length_mm", "flipper_length_mm"],
    "Model 3": ["bill_length_mm", "flipper_length_mm", "body_mass_g"],
    "Model 4": [
        "bill_length_mm", "flipper_length_mm", "body_mass_g", "year", "species_Chinstrap", "species_Gentoo", "island_Dream", "island_Torgersen", "sex_male"]}

rows = []
for name, cols in models.items():
    model = LinearRegression()
    model.fit(X_train[cols], y_train)
    y_pred = model.predict(X_train[cols])
    X_train[f"{name}_predict"] = y_pred
    rmse = np.sqrt(mean_squared_error(y_train, y_pred))
    r2 = r2_score(y_train, y_pred)
    rows.append({
        "Model": name,
        "Train RMSE": rmse,
        "Train RÂ²": r2})

train_results = pd.DataFrame(rows)
train_results


```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 206}
df_long = X_train[["bill_length_mm", "Model 1_predict", "Model 2_predict",
                   "Model 3_predict", "Model 4_predict"]].copy()
df_long["bill_depth_mm"] = y_train

df_long = df_long.melt(
    id_vars=["bill_length_mm", "bill_depth_mm"],
    value_name="bill_depth_mm_predicted",
    var_name="type")

df_long.head()
```

```{python}
#| colab: {base_uri: https://localhost:8080/, height: 497}
from plotnine import *

(ggplot(df_long,
        aes(x = "bill_length_mm",
            y = "bill_depth_mm",
            color = "type")) +
 geom_point())
```

